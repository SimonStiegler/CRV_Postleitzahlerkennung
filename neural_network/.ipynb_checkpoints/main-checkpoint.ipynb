{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network für klassifizierung von arabischen Zahlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import gzip\n",
    "import struct\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isaac/Documents/master/computer_and_robot_vision/emnist_dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = os.path.abspath(\"./emnist_dataset\")\n",
    "print(dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasse für Model definieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrvModel:\n",
    "    def __init__(self, dataset_folder):\n",
    "        \n",
    "        self.dataset_path = dataset_folder\n",
    "        self.labels = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "        self.num_classes = len(self.labels)\n",
    "        \n",
    "        self.random_seed_num = 21081994\n",
    "        \n",
    "        self.batch_size = 1024\n",
    "        self.epochs = 50\n",
    "        self.save_path = \"./model.h5\"\n",
    "\n",
    "        self.raw_train_img = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-train-images-idx3-ubyte.gz'))\n",
    "        self.raw_train_labels = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-train-labels-idx1-ubyte.gz'))\n",
    "        self.raw_test_img = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-test-images-idx3-ubyte.gz'))\n",
    "        self.raw_test_labels = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-test-labels-idx1-ubyte.gz'))\n",
    "        \n",
    "        self.train_img = self.preprocess_data(self.raw_train_img)\n",
    "        self.test_img = self.preprocess_data(self.raw_test_img)\n",
    "        \n",
    "        self.train_labels = self.one_hot_encode_labels(self.raw_train_labels)\n",
    "        self.test_labels = self.one_hot_encode_labels(self.raw_test_labels)\n",
    "        \n",
    "        self.cnn = tf.keras.models.Sequential()\n",
    "        self.cnn.add(tf.keras.layers.Conv2D(32,\n",
    "                                            kernel_size = (5,5),\n",
    "                                            strides = (2,2),\n",
    "                                            input_shape = (28, 28, 1),\n",
    "                                            activation = \"relu\"))\n",
    "        self.cnn.add(tf.keras.layers.Conv2D(64,\n",
    "                                            kernel_size = (3, 3),\n",
    "                                            activation = \"relu\"))\n",
    "        \n",
    "        self.cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "        self.cnn.add(tf.keras.layers.Flatten())\n",
    "        self.cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "        self.cnn.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "    def read_data(self, path):\n",
    "        print(\"Lese Datenset '%s' ein\" %path)\n",
    "        with gzip.open(path, \"rb\") as f:\n",
    "            z, dtype, dim = struct.unpack(\">HBB\", f.read(4))\n",
    "            print(\"Dimensions:\", dim)\n",
    "            shape = tuple(struct.unpack(\">I\", f.read(4))[0] for d in range(dim))\n",
    "            print(\"Shape:\", shape)\n",
    "            print(\"***********************************************\")\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "        \n",
    "    def show_random_image(self, data_imgs, data_labels):\n",
    "        i = random.randint(0, data_imgs.shape[0])\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.clear()\n",
    "        ax.imshow(data_imgs[i].T, cmap=\"gray\")\n",
    "        title = \"label = %d = %s\" %(data_labels[i], self.labels[data_labels[i]])\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    def preprocess_data(self, raw_data):\n",
    "        normalized_data = raw_data.astype(\"float32\")/255\n",
    "        reshaped_data = normalized_data.reshape(normalized_data.shape[0], 28, 28, 1)\n",
    "        return reshaped_data\n",
    "    \n",
    "    def one_hot_encode_labels(self, raw_labels):\n",
    "        return tf.keras.utils.to_categorical(raw_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/emnist_dataset/emnist-byclass-train-images-idx3-ubyte.gz' ein\n",
      "Dimensions: 3\n",
      "Shape: (697932, 28, 28)\n",
      "***********************************************\n",
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/emnist_dataset/emnist-byclass-train-labels-idx1-ubyte.gz' ein\n",
      "Dimensions: 1\n",
      "Shape: (697932,)\n",
      "***********************************************\n",
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/emnist_dataset/emnist-byclass-test-images-idx3-ubyte.gz' ein\n",
      "Dimensions: 3\n",
      "Shape: (116323, 28, 28)\n",
      "***********************************************\n",
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/emnist_dataset/emnist-byclass-test-labels-idx1-ubyte.gz' ein\n",
      "Dimensions: 1\n",
      "Shape: (116323,)\n",
      "***********************************************\n"
     ]
    }
   ],
   "source": [
    "model = CrvModel(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_random_image(model.raw_train_img, model.raw_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 12, 12, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 232,254\n",
      "Trainable params: 232,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.cnn.summary()\n",
    "model.cnn.compile(loss = \"categorical_crossentropy\",\n",
    "                  optimizer = \"adam\",\n",
    "                  metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 697932 samples, validate on 116323 samples\n",
      "Epoch 1/50\n",
      "697932/697932 [==============================] - 9s 12us/sample - loss: 0.8672 - accuracy: 0.7419 - val_loss: 0.4572 - val_accuracy: 0.8400\n",
      "Epoch 2/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.5067 - accuracy: 0.8270 - val_loss: 0.4139 - val_accuracy: 0.8517\n",
      "Epoch 3/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.4636 - accuracy: 0.8383 - val_loss: 0.3944 - val_accuracy: 0.8569\n",
      "Epoch 4/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.4416 - accuracy: 0.8450 - val_loss: 0.3805 - val_accuracy: 0.8614\n",
      "Epoch 5/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.4266 - accuracy: 0.8487 - val_loss: 0.3748 - val_accuracy: 0.8623\n",
      "Epoch 6/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.4171 - accuracy: 0.8514 - val_loss: 0.3672 - val_accuracy: 0.8647\n",
      "Epoch 7/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.4091 - accuracy: 0.8531 - val_loss: 0.3654 - val_accuracy: 0.8657\n",
      "Epoch 8/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.4030 - accuracy: 0.8546 - val_loss: 0.3608 - val_accuracy: 0.8662\n",
      "Epoch 9/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3974 - accuracy: 0.8561 - val_loss: 0.3581 - val_accuracy: 0.8668\n",
      "Epoch 10/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3933 - accuracy: 0.8570 - val_loss: 0.3574 - val_accuracy: 0.8673\n",
      "Epoch 11/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3887 - accuracy: 0.8584 - val_loss: 0.3540 - val_accuracy: 0.8680\n",
      "Epoch 12/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3854 - accuracy: 0.8590 - val_loss: 0.3524 - val_accuracy: 0.8679\n",
      "Epoch 13/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3828 - accuracy: 0.8599 - val_loss: 0.3524 - val_accuracy: 0.8683\n",
      "Epoch 14/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3798 - accuracy: 0.8607 - val_loss: 0.3511 - val_accuracy: 0.8690\n",
      "Epoch 15/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3777 - accuracy: 0.8611 - val_loss: 0.3490 - val_accuracy: 0.8693\n",
      "Epoch 16/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3749 - accuracy: 0.8619 - val_loss: 0.3499 - val_accuracy: 0.8686\n",
      "Epoch 17/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3733 - accuracy: 0.8622 - val_loss: 0.3487 - val_accuracy: 0.8696\n",
      "Epoch 18/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3708 - accuracy: 0.8627 - val_loss: 0.3471 - val_accuracy: 0.8702\n",
      "Epoch 19/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3697 - accuracy: 0.8633 - val_loss: 0.3470 - val_accuracy: 0.8702\n",
      "Epoch 20/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3673 - accuracy: 0.8640 - val_loss: 0.3468 - val_accuracy: 0.8699\n",
      "Epoch 21/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3656 - accuracy: 0.8645 - val_loss: 0.3470 - val_accuracy: 0.8697\n",
      "Epoch 22/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3654 - accuracy: 0.8642 - val_loss: 0.3461 - val_accuracy: 0.8698\n",
      "Epoch 23/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3637 - accuracy: 0.8646 - val_loss: 0.3446 - val_accuracy: 0.8707\n",
      "Epoch 24/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3621 - accuracy: 0.8651 - val_loss: 0.3451 - val_accuracy: 0.8714\n",
      "Epoch 25/50\n",
      "417792/697932 [================>.............] - ETA: 2s - loss: 0.3597 - accuracy: 0.8659"
     ]
    }
   ],
   "source": [
    "model.trained = model.cnn.fit(model.train_img,\n",
    "              model.train_labels,\n",
    "              batch_size = model.batch_size,\n",
    "              epochs = model.epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = (model.test_img, model.test_labels))\n",
    "\n",
    "model.cnn.save(model.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), dpi=96)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model.trained.history['loss'])\n",
    "plt.plot(model.trained.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model.trained.history['accuracy'])\n",
    "plt.plot(model.trained.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
