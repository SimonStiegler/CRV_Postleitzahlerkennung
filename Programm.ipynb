{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitdlcondafb9c8a2b77894feca7a3c3d76517a545",
   "display_name": "Python 3.7.7 64-bit ('dl': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Program f√ºr Roboter- und Computervision"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importieren der Bibliotheken"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "# for Rotation only cutting the picture\n",
    "import argparse\n",
    "import pydash\n",
    "import random\n",
    "import imutils as im\n",
    "import csv\n",
    "import sqlite3\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "import struct\n",
    "import os\n",
    "\n",
    "from mlxtend.data import loadlocal_mnist"
   ]
  },
  {
   "source": [
    "## Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"./Briefe/Brief_rotated150.jpg\"\n",
    "# Kernel\n",
    "blurring = 0\n",
    "dilateErode = 1\n",
    "dilateKernel = np.ones((dilateErode,dilateErode), \"uint8\")\n",
    "erodeKernel = np.ones((dilateErode,dilateErode), \"uint8\")\n",
    "# CharacterKernel\n",
    "characterDilateErode = 5\n",
    "characterDK = np.ones((characterDilateErode,characterDilateErode),\"uint8\")\n",
    "characterEK = np.ones((characterDilateErode,characterDilateErode),\"uint8\")\n",
    "\n",
    " \n",
    "# C5/6 Scale  220x110\n",
    "C_5_6_Metrics= [220,110]\n",
    "C_5_6_Scale = [1.8,2.4]\n",
    "stampZone = [74,40]\n",
    "margin = 15\n",
    "stampMinSize=[28,15]"
   ]
  },
  {
   "source": [
    "## Vorbereitung des Bildes\n",
    "\n",
    "<img src=\"./README_pictures/Normen_Brief.png\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "    # Lesen des Bilds\n",
    "image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "if image is None:\n",
    "      raise SystemExit(\"Imagepath is not right\")\n",
    "height,width,channels = image.shape\n",
    "height-=1\n",
    "width-=1\n",
    "showImage = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    # Zeigen des Bilds\n",
    "plt.imshow(showImage)\n",
    "plt.title(\"Original\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Binarisierung\n",
    "https://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-3-otsu-thresholding/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh1 = cv2.adaptiveThreshold(blurred,255,125,cv2.THRESH_BINARY,11,5)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "plt.imshow(gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"Gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th,binImg  = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(binImg,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erode = cv2.erode(binImg,erodeKernel,iterations=1)\n",
    "plt.imshow(erode, cmap=\"gray\")\n",
    "plt.title(\"dilate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilate = cv2.dilate(erode,dilateKernel,iterations=1)\n",
    "plt.imshow(dilate, cmap=\"gray\")\n",
    "plt.title(\"erode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(dilate,0,30)\n",
    "height,width = canny.shape\n",
    "plt.imshow(canny, cmap=\"gray\")\n",
    "plt.title(\"Canny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_straight(cannyImg):\n",
    "        img,contours,hierachies = cv2.findContours(cannyImg,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "        rotAngle = 0\n",
    "        for i,contour in enumerate(contours):\n",
    "            hNext, hPrev, hChild, hParent = hierachies[0][i]\n",
    "            minArea = cv2.minAreaRect(contour)\n",
    "            contWidth = minArea[1][0]\n",
    "            contHeight = minArea[1][1]\n",
    "            contAngle = minArea[2]       \n",
    "            #print(contHeight, contWidth, contAngle)\\n\",\n",
    "    \n",
    "            if (contWidth<contHeight):\n",
    "                height = contWidth\n",
    "                width = contHeight\n",
    "                rotAngle = 90\n",
    "            else:\n",
    "                height = contHeight\n",
    "                width = contWidth\n",
    "                rotAngle = 0\n",
    "            \n",
    "            if(height==0) or (width==0):\n",
    "                scale = -1\n",
    "                fillFactor = -1\n",
    "            else:\n",
    "                scale = width/height\n",
    "                area_rect = height*width\n",
    "                letter_rect = cv2.contourArea(contour)\n",
    "                fillFactor = letter_rect/area_rect\n",
    "                #print(\\\"Contour: \\\",i, \\\" / scale: \\\",scale,\\\" / width: \\\",width, \\\" / height:\\\",height,\\\"/ Fill:\\\",fillFactor)\n",
    "            if(scale>C_5_6_Scale[0] and scale<C_5_6_Scale[1]) and (hChild != -1) and (hParent == -1) and (fillFactor > 0.95):\n",
    "                #print(\\\"ALL CRITERIA TRUE: Contour: \\\",i, \\\" / scale: \\\",scale,\\\" / width: \\\",width, \\\" / height:\\\",height,\\\"/ Fill:\\\",fillFactor)\n",
    "                rotAngle -= contAngle\n",
    "                return im.rotate_bound(cannyImg,rotAngle), rotAngle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(canny,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[aligned_image,letterAngle] = align_straight(canny)\n",
    "plt.imshow(aligned_image,cmap=\"gray\")\n",
    "plt.title(\"straight-aligned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,contours,hierachy = cv2.findContours(aligned_image,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "# Hierarchie [Previous, Next, Child, Parent]"
   ]
  },
  {
   "source": [
    "def sizeSort(element):\n",
    "    return len(element)\n",
    "contours.sort(reverse=True,key=sizeSort)\n",
    "# Print the 5 biggest Contoursizes\n",
    "for index,contour in enumerate(contours):\n",
    "    if(index<6):\n",
    "        print(contour.size)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Get the Moments\n",
    "https://docs.opencv.org/3.1.0/dd/d49/tutorial_py_contour_features.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/3.1.0/dd/d49/tutorial_py_contour_features.html\n",
    "def findLetter(img):\n",
    "        img,contours,hierachies = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE) \n",
    "        letter ={} \n",
    "        for i,contour in enumerate(contours): \n",
    "            hNext, hPrev, hChild, hParent = hierachies[0][i] \n",
    "            minArea = cv2.minAreaRect(contour) \n",
    "             \n",
    "            rectWidth = minArea[1][0] \n",
    "            rectHeight = minArea[1][1] \n",
    "            if (rectHeight<rectWidth): \n",
    "                height = rectHeight \n",
    "                width = rectWidth \n",
    "            else: \n",
    "                height = rectWidth \n",
    "                width = rectHeight \n",
    "             \n",
    "            if(height==0 or width==0): \n",
    "                scale = -1 \n",
    "                fillFactor = -1 \n",
    "            else: \n",
    "                scale = width/height \n",
    "                area_rect = height*width \n",
    "                letter_rect = cv2.contourArea(contour) \n",
    "                fillFactor = letter_rect/area_rect \n",
    "                 \n",
    "            if(scale>C_5_6_Scale[0] and scale<C_5_6_Scale[1]) and (hChild != -1) and (hParent == -1) and (fillFactor > 0.95): \n",
    "                #print(\\\"Contour: \\\",i, \\\" / scale: \\\",scale,\\\" / width: \\\",width, \\\" / height:\\\",height,\\\"/ Fill:\\\",fillFactor) \n",
    "                letter = { \n",
    "                    \"width\": int(width), \n",
    "                    \"height\" : int(height), \n",
    "                    \"centerX\" : int(minArea[0][0]), \n",
    "                    \"centerY\" : int(minArea[0][1]), \n",
    "                    \"contour\": contour \n",
    "                    } \n",
    "                return letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letterValue = findLetter(aligned_image)\n",
    "if letterValue is None:\n",
    "      raise SystemExit(\"letter not found\")\n",
    "# Highlight the Contour of Find Letter and show center of Letter\n",
    "highlightedContour = aligned_image.copy()\n",
    "highlightedContour = cv2.circle(highlightedContour,(letterValue[\"centerX\"],letterValue[\"centerY\"]),radius=30, color=(0,0,255),thickness=-1)\n",
    "cv2.drawContours(highlightedContour, letterValue[\"contour\"], -1, (0, 0, 255), 20) \n",
    "plt.imshow(highlightedContour)"
   ]
  },
  {
   "source": [
    "## ROI of Letter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xStart = int(letterValue[\"centerX\"]-letterValue[\"width\"]/2)\n",
    "xEnd = int(letterValue[\"centerX\"]+letterValue[\"width\"]/2)\n",
    "yStart = int(letterValue[\"centerY\"]-letterValue[\"height\"]/2)\n",
    "yEnd = int(letterValue[\"centerY\"]+letterValue[\"height\"]/2)\n",
    "letter =aligned_image[yStart:yEnd,xStart:xEnd]\n",
    "plt.imshow(letter, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelPerMM = letterValue[\"width\"]/C_5_6_Metrics[0]\n",
    "# StampZone [width, height] amount of Pixel\n",
    "stampZoneMetrics = [int(stampZone[0]*pixelPerMM),int(stampZone[1]*pixelPerMM)]\n",
    "# get the rigth Top StampZone\n",
    "rightTop = letter[0:stampZoneMetrics[1],letterValue[\"width\"]-stampZoneMetrics[0]:letterValue[\"width\"]]\n",
    "plt.imshow(rightTop, cmap=\"gray\")"
   ]
  },
  {
   "source": [
    "### Check if stamp is there"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def checkStamp(stampZone, pixelPerMM):  \n",
    "    imgStamp,cStamp,hStamp = cv2.findContours(stampZone,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    stamp_found = False   \n",
    "    if (len(cStamp)!=0):                #No contour found  \n",
    "        for index,contour in enumerate(cStamp):           \n",
    "            #( center (x,y), (width, height), angle of rotation ).  \n",
    "            hNext, hPrev, hChild, hParent = hStamp[0][index]  \n",
    "            approx = cv2.approxPolyDP(contour,10,True)  \n",
    "            minArea = cv2.minAreaRect(approx)  \n",
    "            #print(minArea)  \n",
    "            width = minArea[1][0]  \n",
    "            height = minArea[1][1]                \n",
    "            if (hChild != -1) and (hParent == -1):      #Extract Parent contour  \n",
    "                # stamp minSize 22x28  \n",
    "                contourWidth = width/pixelPerMM  \n",
    "                contourHeigth = height/pixelPerMM  \n",
    "                #print(contourHeigth, contourWidth)  \n",
    "                if((contourWidth >= stampMinSize[0]) and (contourHeigth >= stampMinSize[1])):  \n",
    "                    stamp_found = True  \n",
    "                else:  \n",
    "                    stamp_found = False  \n",
    "    return stamp_found  \n",
    "       \n",
    "def align_correct(roiLetter,pixelPerMM):\n",
    "    height,width = roiLetter.shape\n",
    "    # StampZone [width, height] amount of Pixel\n",
    "    stampZoneMetrics = [int(stampZone[0]*pixelPerMM),int(stampZone[1]*pixelPerMM)]\n",
    "    # get the rigth Top StampZone\n",
    "    offset = 20\n",
    "    rightTop = roiLetter[0+offset:stampZoneMetrics[1]-offset,width-stampZoneMetrics[0]+offset:width-offset]\n",
    "    stamp_found = checkStamp(rightTop,pixelPerMM) \n",
    "    if stamp_found:\n",
    "        return roiLetter,0, stamp_found\n",
    "    else:\n",
    "        return im.rotate_bound(roiLetter,180),180, stamp_found\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLetter(image): \n",
    "    #Preprocessing \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "    th,binImg  = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY) \n",
    "    erode = cv2.erode(binImg,erodeKernel,iterations=1) \n",
    "    dilate = cv2.dilate(erode,dilateKernel,iterations=1)  \n",
    "    #Not needed! canny = cv2.Canny(dilate,0,30) \n",
    "      \n",
    "    #Rotate image wide side down \n",
    "    aligned_image,letterAngle = align_straight(dilate) \n",
    "    height, width = aligned_image.shape[:2] \n",
    "      \n",
    "    #Extract ROI of letter and calculate pixel Size \n",
    "    letterValue = findLetter(aligned_image) \n",
    "    if letterValue is None: \n",
    "        raise SystemExit(\"letter not found\") \n",
    "    xStart = int(letterValue[\"centerX\"]-letterValue[\"width\"]/2) \n",
    "    xEnd = int(letterValue[\"centerX\"]+letterValue[\"width\"]/2) \n",
    "    yStart = int(letterValue[\"centerY\"]-letterValue[\"height\"]/2) \n",
    "    yEnd = int(letterValue[\"centerY\"]+letterValue[\"height\"]/2) \n",
    "    letter = aligned_image[yStart:yEnd,xStart:xEnd] \n",
    "    pixelPerMM = letterValue[\"width\"]/C_5_6_Metrics[0] \n",
    "      \n",
    "    #Align images with stamp in the upper right corner \n",
    "    correct_aligned,turnAngle,found = align_correct(letter, pixelPerMM) \n",
    "      \n",
    "    #Calculate turning angle and return extracted Letter \n",
    "    letterAngle = (letterAngle + turnAngle)%360 \n",
    "      \n",
    "    if found: \n",
    "        extracted = im.rotate_bound(gray,letterAngle)[yStart:yEnd,xStart:xEnd] \n",
    "    else: \n",
    "        extracted = im.rotate_bound(gray,letterAngle)[height-yEnd:height-yStart,width-xEnd:width-xStart] \n",
    "      \n",
    "    return extracted, letterAngle, pixelPerMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letterGray, letterAngle, pixelPerMM = extractLetter(image)\n",
    "plt.imshow(letterGray,cmap=\"gray\")"
   ]
  },
  {
   "source": [
    "## Get AddressField"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = letterGray.shape\n",
    "pixelMargin = margin*pixelPerMM\n",
    "startX = int(pixelMargin)\n",
    "endX = int(width-pixelMargin)\n",
    "startY = int(stampZone[1]*pixelPerMM)\n",
    "endY = int(height-pixelMargin)\n",
    "addressField = letterGray[startY:endY, startX:endX]\n",
    "[heightAF, widthAF] = addressField.shape\n",
    "plt.imshow(addressField, cmap=\"gray\")\n",
    "plt.title(\"addressfield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBlurValue(height, blurScale):\n",
    "    scale = int(height / blurScale)\n",
    "    if scale % 2 == 0:\n",
    "        scale += 1\n",
    "    if scale < 3:\n",
    "        scale = 3\n",
    "    print(\"Value of the blur: \" + str(scale))\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurrValueAF = getBlurValue(heightAF, 97)\n",
    "blurrAFKernel = (blurrValueAF, blurrValueAF)\n",
    "blurrAF = cv2.blur(addressField, blurrAFKernel)\n",
    "plt.imshow(blurrAF, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassBorder(grayImage, area=[0, 255]):\n",
    "    flattenArray = grayImage.flatten()\n",
    "    filtered = pydash.filter_(\n",
    "        flattenArray, lambda x: x > area[0] and x < area[1])\n",
    "    amount, binEdges, _ = plt.hist(filtered, bins=9)\n",
    "    maxBeginEdge = binEdges[np.where(amount == amount.max())]\n",
    "    print(\"area: \" + str(area))\n",
    "    print(\"amount of pixels: \" + str(len(flattenArray)))\n",
    "    print(\"Begin of Edge of the max Grayscale Histogram: \" + str(maxBeginEdge))\n",
    "    binEgde = int(maxBeginEdge - 2)\n",
    "    return binEgde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binEdge = getClassBorder(addressField, [50, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th, binAF = cv2.threshold(blurrAF, binEdge, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(binAF, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(binAF, 100, 200)\n",
    "plt.imshow(canny, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgAF, contoursAF, hierachyAF = cv2.findContours(\n",
    "    binAF, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "contourImg = np.zeros((heightAF, widthAF, 3))\n",
    "for index, contour in enumerate(contoursAF):\n",
    "    r = random.random()\n",
    "    g = random.random()\n",
    "    b = random.random()\n",
    "    cv2.drawContours(contourImg, contoursAF, index, (r, g, b), 5)\n",
    "plt.imshow(contourImg)"
   ]
  },
  {
   "source": [
    "## Display Function\n",
    "https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, cols=1, titles=None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "\n",
    "    cols (Default = 1): Number of columns in figure (number of rows is \n",
    "                        set to np.ceil(n_images/float(cols))).\n",
    "\n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['Image (%d)' % i for i in range(1, n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "## Extract the Characters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "for index, contour in enumerate(contoursAF):\n",
    "    # [x,y,width,height]\n",
    "    rect = cv2.boundingRect(contour)\n",
    "    x = rect[0]\n",
    "    y = rect[1]\n",
    "    width = rect[2]\n",
    "    height = rect[3]\n",
    "    # 0 because of the outer\n",
    "    if(width > 5 and height > 5 and width != widthAF and hierachyAF[0][index][3] == 0):\n",
    "        img = binAF[y:y+height, x:x+width]\n",
    "        character = {\n",
    "            \"img\": img,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"x\": x,\n",
    "            \"y\": y\n",
    "        }\n",
    "        characters.append(character)\n",
    "        # plt.imshow(character,cmap=\"gray\")\n",
    "if len(characters) == 0:\n",
    "    raise SystemExit(\"No Character with needed size found\")\n",
    "show_images(pydash.map_(characters, \"img\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centerPoints = characters\n",
    "print(pydash.map_(characters, [\"x\"]))\n",
    "print(pydash.map_(characters, [\"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_width = np.sum(pydash.map_(characters, \"width\"))/len(characters)\n",
    "mean_height = np.sum(pydash.map_(characters, \"height\"))/len(characters)\n",
    "\n",
    "\n",
    "def sortY(element):\n",
    "    return element[\"y\"]\n",
    "\n",
    "\n",
    "centerPoints.sort(key=sortY)\n",
    "print(mean_width)\n",
    "print(mean_height)\n",
    "print(pydash.map_(characters, [\"x\"]))\n",
    "print(pydash.map_(characters, [\"y\"]))"
   ]
  },
  {
   "source": [
    "## Get the Rowedges"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://numpy.org/doc/stable/reference/generated/numpy.histogram.html\n",
    "amount, binEdges, _ = plt.hist(pydash.map_(characters, [\"y\"]), bins=\"auto\")\n",
    "rowEdges = []\n",
    "for i, yValue in enumerate(amount):\n",
    "    if(yValue > 0):\n",
    "        rowEdges.append([binEdges[i], binEdges[i+1]])\n",
    "\n",
    "\n",
    "print(rowEdges)\n",
    "print(amount)"
   ]
  },
  {
   "source": [
    "## Get the Rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "rows = []\n",
    "lastChar = characters[len(characters)-1]\n",
    "for edge in rowEdges:\n",
    "    rowElements = []\n",
    "    for index, character in enumerate(characters):\n",
    "        if(edge[0] <= character[\"y\"]):\n",
    "            if(edge[1] >= character[\"y\"]):\n",
    "                rowElements.append(character)\n",
    "                # for last Edge that the rowElements are added\n",
    "                if(lastChar == character):\n",
    "                    rows.append(rowElements)\n",
    "            else:\n",
    "                rows.append(rowElements)\n",
    "                break\n",
    "print(len(rows))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Displaying the Rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortX(element):\n",
    "    return element[\"x\"]\n",
    "\n",
    "for row in rows:\n",
    "    row.sort(key=sortX)\n",
    "    show_images(pydash.map_(row,\"img\")) "
   ]
  },
  {
   "source": [
    "## Get PLZ\n",
    "From Last Row\n",
    "\n",
    "https://www.sekretaria.de/bueroorganisation/korrespondenz/din-5008/anschrift/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastRow = rows[len(rows)-1]\n",
    "PLZ = lastRow[0:5]\n",
    "show_images(pydash.map_(PLZ,\"img\"))"
   ]
  },
  {
   "source": [
    "# Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.abspath(\"./emnist_dataset\")\n",
    "print(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrvModel:\n",
    "    def __init__(self, dataset_folder):\n",
    "        \n",
    "        # Constants and Paths for Networks\n",
    "        self.dataset_path = dataset_folder\n",
    "        self.emnist_classes = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "        self.num_emnist_classes = len(self.emnist_classes)\n",
    "        self.mnist_classes = \"0123456789\"\n",
    "        self.num_mnist_classes = len(self.mnist_classes)\n",
    "        self.emnist_letter_classes = \"-abcdefghijklmnopqrstuvwxyz\"\n",
    "        self.num_emnist_letter_classes = len(self.emnist_letter_classes)\n",
    "        self.german_digits_classes = \"0123456789\"\n",
    "        self.num_german_digits_classes = len(self.german_digits_classes)\n",
    "        \n",
    "        # Constants for training and paths to save models\n",
    "        self.batch_size = 1024\n",
    "        self.epochs = 200\n",
    "        self.emnist_save_path = \"./emnist_byclass.h5\"\n",
    "        self.emnist_letter_save_path = \"./emnist_letter.h5\"\n",
    "        self.mnist_save_path = \"./mnist.h5\"\n",
    "        self.german_digit_network_save_path = \"./german_digits_network.h5\"\n",
    "\n",
    "        # Read in or download raw data for models\n",
    "        self.raw_emnist_train_img = self.read_local_data(os.path.join(dataset_folder, 'emnist-byclass-train-images-idx3-ubyte.gz'))\n",
    "        self.raw_emnist_train_labels = self.read_local_data(os.path.join(dataset_folder, 'emnist-byclass-train-labels-idx1-ubyte.gz'))\n",
    "        self.raw_emnist_test_img = self.read_local_data(os.path.join(dataset_folder, 'emnist-byclass-test-images-idx3-ubyte.gz'))\n",
    "        self.raw_emnist_test_labels = self.read_local_data(os.path.join(dataset_folder, 'emnist-byclass-test-labels-idx1-ubyte.gz'))\n",
    "\n",
    "        self.raw_emnist_letter_train_img = self.read_local_data(os.path.join(dataset_folder, 'emnist-letters-train-images-idx3-ubyte.gz'))\n",
    "        self.raw_emnist_letter_train_labels = self.read_local_data(os.path.join(dataset_folder, 'emnist-letters-train-labels-idx1-ubyte.gz'))\n",
    "        self.raw_emnist_letter_test_img = self.read_local_data(os.path.join(dataset_folder, 'emnist-letters-test-images-idx3-ubyte.gz'))\n",
    "        self.raw_emnist_letter_test_labels = self.read_local_data(os.path.join(dataset_folder, 'emnist-letters-test-labels-idx1-ubyte.gz'))\n",
    "\n",
    "        (self.raw_mnist_train_img, self.raw_mnist_train_labels), (self.raw_mnist_test_img, self.raw_mnist_test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "        self.raw_german_digit_train_img, self.raw_german_digit_train_labels = self.load_german_digits('german_digits_datasets/german_train.data', 'german_digits_datasets/german_train.labels')\n",
    "        self.raw_german_digit_test_img, self.raw_german_digit_test_labels = self.load_german_digits('german_digits_datasets/german_test.data', 'german_digits_datasets/german_test.labels')\n",
    "\n",
    "        \n",
    "        # Preprocess data\n",
    "        self.emnist_train_img = self.preprocess_data(self.raw_emnist_train_img)\n",
    "        self.emnist_test_img = self.preprocess_data(self.raw_emnist_test_img)\n",
    "        self.emnist_train_labels = tf.keras.utils.to_categorical(self.raw_emnist_train_labels)\n",
    "        self.emnist_test_labels = tf.keras.utils.to_categorical(self.raw_emnist_test_labels)\n",
    "        \n",
    "        self.mnist_train_img = self.preprocess_data(self.raw_mnist_train_img)\n",
    "        self.mnist_test_img = self.preprocess_data(self.raw_mnist_test_img)\n",
    "        self.mnist_train_labels = tf.keras.utils.to_categorical(self.raw_mnist_train_labels)\n",
    "        self.mnist_test_labels = tf.keras.utils.to_categorical(self.raw_mnist_test_labels)\n",
    "\n",
    "        self.emnist_letter_train_img = self.preprocess_data(self.raw_emnist_letter_train_img)\n",
    "        self.emnist_letter_test_img = self.preprocess_data(self.raw_emnist_letter_test_img)\n",
    "        self.emnist_letter_train_labels = tf.keras.utils.to_categorical(self.raw_emnist_letter_train_labels)\n",
    "        self.emnist_letter_test_labels = tf.keras.utils.to_categorical(self.raw_emnist_letter_test_labels)\n",
    "\n",
    "        self.german_digit_train_img = self.preprocess_data(self.raw_german_digit_train_img)\n",
    "        self.german_digit_test_img = self.preprocess_data(self.raw_german_digit_test_img)\n",
    "        self.german_digit_train_labels = tf.keras.utils.to_categorical(self.raw_german_digit_train_labels)\n",
    "        self.german_digit_test_labels = tf.keras.utils.to_categorical(self.raw_german_digit_test_labels)\n",
    "\n",
    "        # Earlystopping Callback\n",
    "        self.early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                                    min_delta=0.002,\n",
    "                                                                    patience=10,\n",
    "                                                                    verbose = 1,\n",
    "                                                                    restore_best_weights=True)\n",
    "                                                                    \n",
    "        self.german_digits_save_weights_callback = tf.keras.callbacks.ModelCheckpoint(self.german_digit_network_save_path,\n",
    "                                                        monitor=\"val_loss\",\n",
    "                                                        verbose=1,\n",
    "                                                        save_best_only=True,\n",
    "                                                        save_weights_only=True\n",
    "                                                    )\n",
    "\n",
    "\n",
    "        # Setup network architecture\n",
    "        self.emnist_cnn = self.setup_network(self.num_emnist_classes)\n",
    "        self.emnist_letter_cnn = self.setup_network(self.num_emnist_letter_classes)\n",
    "        self.mnist_cnn = self.setup_network(self.num_mnist_classes)\n",
    "        self.german_digits_network = self.setup_network(self.num_german_digits_classes)\n",
    "\n",
    "\n",
    "    \n",
    "    # Function Definitions\n",
    "    def load_german_digits(self, img_path, labels_path):\n",
    "        train_img, train_labels = loadlocal_mnist(\n",
    "            images_path=img_path, \n",
    "            labels_path=labels_path)\n",
    "        train_img = train_img.reshape(train_img.shape[0], 28, 28)\n",
    "        return train_img, train_labels\n",
    "        \n",
    "    def read_local_data(self, path):\n",
    "        print(\"Lese Datenset '%s' ein\" %path)\n",
    "        with gzip.open(path, \"rb\") as f:\n",
    "            z, dtype, dim = struct.unpack(\">HBB\", f.read(4))\n",
    "            print(\"Dimensions:\", dim)\n",
    "            shape = tuple(struct.unpack(\">I\", f.read(4))[0] for d in range(dim))\n",
    "            print(\"Shape:\", shape)\n",
    "            print(\"***********************************************\")\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "        \n",
    "    def show_random_image(self, data_imgs, classes, data_labels):\n",
    "        i = random.randint(0, data_imgs.shape[0])\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.clear()\n",
    "        ax.imshow(data_imgs[i].T, cmap=\"gray\")\n",
    "        title = \"label = %d = %s\" %(data_labels[i], classes[data_labels[i]])\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    def preprocess_data(self, raw_data):\n",
    "        normalized_data = raw_data.astype(\"float32\")/255\n",
    "        reshaped_data = normalized_data.reshape(normalized_data.shape[0], 28, 28, 1)\n",
    "        return reshaped_data\n",
    "\n",
    "    def setup_network(self, num_classes):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "source": [
    "## Model initialisieren"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrvModel(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.show_random_image(model.raw_emnist_train_img, model.emnist_classes, model.raw_emnist_train_labels)\n",
    "model.show_random_image(model.raw_mnist_train_img, model.mnist_classes, model.raw_mnist_train_labels)\n",
    "model.show_random_image(model.raw_emnist_letter_train_img, model.emnist_letter_classes, model.raw_emnist_letter_train_labels)\n",
    "model.show_random_image(model.raw_german_digit_train_img, model.german_digits_classes, model.raw_german_digit_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Full Emnist Neural Network\")\n",
    "\n",
    "model.emnist_cnn.summary()\n",
    "model.emnist_cnn.compile(loss = \"categorical_crossentropy\",\n",
    "                         optimizer = \"adam\",\n",
    "                         metrics = [\"accuracy\"],\n",
    "                         callbacks = [model.early_stopping_callback])\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Emnist Letter Neural Network\")\n",
    "model.emnist_letter_cnn.summary()\n",
    "model.emnist_letter_cnn.compile(loss = \"categorical_crossentropy\",\n",
    "                         optimizer = \"adam\",\n",
    "                         metrics = [\"accuracy\"],\n",
    "                         callbacks = [model.early_stopping_callback])\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Mnist Neural Network\")\n",
    "model.mnist_cnn.summary()\n",
    "model.mnist_cnn.compile(loss = \"categorical_crossentropy\", \n",
    "                        optimizer = \"adam\",\n",
    "                        metrics = [\"accuracy\"])\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"German Digits Network\")\n",
    "model.german_digits_network.summary()\n",
    "model.german_digits_network.compile(loss = \"categorical_crossentropy\", \n",
    "                        optimizer = \"adam\",\n",
    "                        metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''                                                                                              \n",
    "print(\"*******************************************************************\")\n",
    "print(\"Train Emnist Model\")\n",
    "print(\"*******************************************************************\")\n",
    "\n",
    "model.emnist_trained = model.emnist_cnn.fit(model.emnist_train_img,\n",
    "              model.emnist_train_labels,\n",
    "              batch_size = model.batch_size,\n",
    "              epochs = model.epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = (model.emnist_test_img, model.emnist_test_labels),\n",
    "              callbacks = [model.early_stopping_callback])\n",
    "\n",
    "model.emnist_cnn.save(model.emnist_save_path)\n",
    "\n",
    "print(\"*******************************************************************\")\n",
    "print(\"Train Emnist Letter Model\")\n",
    "print(\"*******************************************************************\")\n",
    "\n",
    "model.emnist_letter_trained = model.emnist_letter_cnn.fit(model.emnist_letter_train_img,\n",
    "              model.emnist_letter_train_labels,\n",
    "              batch_size = model.batch_size,\n",
    "              epochs = model.epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = (model.emnist_letter_test_img, model.emnist_letter_test_labels),\n",
    "              callbacks = [model.early_stopping_callback])\n",
    "\n",
    "model.emnist_letter_cnn.save(model.emnist_letter_save_path)\n",
    "\n",
    "\n",
    "print(\"*******************************************************************\")\n",
    "print(\"Train Mnist Letter Model\")\n",
    "print(\"*******************************************************************\")\n",
    "\n",
    "model.mnist_trained = model.mnist_cnn.fit(model.mnist_train_img,\n",
    "                                    model.mnist_train_labels,\n",
    "                                    batch_size = model.batch_size,\n",
    "                                    epochs = model.epochs,\n",
    "                                    verbose = 1,\n",
    "                                    validation_data = (model.mnist_test_img, model.mnist_test_labels),\n",
    "                                    callbacks = [model.early_stopping_callback])\n",
    "\n",
    "model.mnist_cnn.save(model.mnist_save_path)\n",
    "\n",
    "\n",
    "print(\"*******************************************************************\")\n",
    "print(\"Train German Digits Model\")\n",
    "print(\"*******************************************************************\")\n",
    "\n",
    "model.german_digits_trained = model.german_digits_network.fit(model.german_digit_train_img,\n",
    "                                    model.german_digit_train_labels,\n",
    "                                    batch_size = model.batch_size,\n",
    "                                    epochs = model.epochs,\n",
    "                                    verbose = 1,\n",
    "                                    validation_data = (model.german_digit_test_img, model.german_digit_test_labels),\n",
    "                                    callbacks = [model.german_digits_save_weights_callback]\n",
    "                                )\n",
    "\n",
    "model.german_digits_network.load_weights(model.german_digit_network_save_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.emnist_cnn.load_weights(model.emnist_save_path)\n",
    "model.emnist_letter_cnn.load_weights(model.emnist_letter_save_path)\n",
    "model.mnist_cnn.load_weights(model.mnist_save_path)\n",
    "model.german_digits_network.load_weights(model.german_digit_network_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(model_name, model_history):\n",
    "    plt.figure()\n",
    "    plt.suptitle(model_name, fontsize=16)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(model_history['loss'])\n",
    "    plt.plot(model_history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(model_history['accuracy'])\n",
    "    plt.plot(model_history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_result(\"Emnist Full Network\", model.emnist_trained.history)\n",
    "#visualize_result(\"Emnist Letter Network\", model.emnist_letter_trained.history)\n",
    "#visualize_result(\"Mnist Network\", model.mnist_trained.history)\n",
    "#visualize_result(\"German Digits Network\", model.german_digits_trained.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_results = model.emnist_cnn.evaluate(model.emnist_test_img, model.emnist_test_labels, verbose=0)\n",
    "emnist_letter_results = model.emnist_letter_cnn.evaluate(model.emnist_letter_test_img, model.emnist_letter_test_labels, verbose=0)\n",
    "mnist_results = model.mnist_cnn.evaluate(model.mnist_test_img, model.mnist_test_labels, verbose=0)\n",
    "german_digits_results = model.german_digits_network.evaluate(model.german_digit_test_img, model.german_digit_test_labels, verbose=0)\n",
    "\n",
    "print('Emnist Loss: %.2f%%, Accuracy: %.2f%%' % (emnist_results[0]*100, emnist_results[1]*100))\n",
    "print('Emnist Letter Loss: %.2f%%, Accuracy: %.2f%%' % (emnist_letter_results[0]*100, emnist_letter_results[1]*100))\n",
    "print('Mnist Loss: %.2f%%, Accuracy: %.2f%%' % (mnist_results[0]*100, mnist_results[1]*100))\n",
    "print('German Digits Loss: %.2f%%, Accuracy: %.2f%%' % (german_digits_results[0]*100, german_digits_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_segmented_image(img):\n",
    "    img = ~img\n",
    "    s = max(img.shape[0:2])\n",
    "    f = np.zeros((s, s), np.uint8)\n",
    "    ax, ay = (s - img.shape[1])//2, (s - img.shape[0])//2\n",
    "    f[ay:img.shape[0]+ay, ax:ax+img.shape[1]] = img\n",
    "    img = cv2.resize(img, (28,28))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "PLZ_array = np.array(pydash.map_(PLZ,\"img\"))\n",
    "for i, img in enumerate(PLZ_array):\n",
    "    PLZ_array[i] = preprocess_segmented_image(img)\n",
    "\n",
    "#predictions = model.german_digits_network.predict(PLZ_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(116323, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(model.emnist_test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in PLZ_array\n",
    "model.german_digits_network.predict(PLZ_array)"
   ]
  },
  {
   "source": [
    "# Abgleich mit Datenbank"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_town(plz):\n",
    "#     # Verbindung, Cursor\n",
    "#     connection = sqlite3.connect(\"orteDE.db\")\n",
    "#     cursor = connection.cursor()\n",
    "\n",
    "#     # SQL-Abfrage\n",
    "#     sql = \"SELECT ortsname, bundesland FROM orte WHERE plz=\"+str(plz)\n",
    "\n",
    "#     # Kontrollausgabe der SQL-Abfrage\n",
    "#     # print(sql) \n",
    "\n",
    "#     # Absenden der SQL-Abfrage\n",
    "#     # Empfang des Ergebnisses\n",
    "#     cursor.execute(sql)\n",
    "\n",
    "#     # Ausgabe des Ergebnisses\n",
    "#     results = cursor.fetchall()\n",
    "#     #for dsatz in cursor:\n",
    "#     #    ort = dsatz[0]\n",
    "#     #    bundesland = dsatz[1]\n",
    "        \n",
    "#     # Verbindung beenden\n",
    "#     connection.close()\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Example for single PLZ\n",
    "# print(get_town(74246))\n",
    "# #Example for multiple PLZ\n",
    "# print(get_town(27367))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}