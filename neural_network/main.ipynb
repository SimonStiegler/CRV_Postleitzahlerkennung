{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network für klassifizierung von arabischen Zahlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import gzip\n",
    "import struct\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isaac/Documents/master/computer_and_robot_vision/CRV_Postleitzahlerkennung/neural_network/emnist_dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = os.path.abspath(\"./emnist_dataset\")\n",
    "print(dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasse für Model definieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrvModel:\n",
    "    def __init__(self, dataset_folder):\n",
    "        \n",
    "        self.dataset_path = dataset_folder\n",
    "        self.labels = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "        self.num_classes = len(self.labels)\n",
    "        \n",
    "        self.random_seed_num = 21081994\n",
    "        \n",
    "        self.batch_size = 1024\n",
    "        self.epochs = 50\n",
    "        self.save_path = \"./model.h5\"\n",
    "\n",
    "        self.raw_train_img = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-train-images-idx3-ubyte.gz'))\n",
    "        self.raw_train_labels = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-train-labels-idx1-ubyte.gz'))\n",
    "        self.raw_test_img = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-test-images-idx3-ubyte.gz'))\n",
    "        self.raw_test_labels = self.read_data(os.path.join(dataset_folder, 'emnist-byclass-test-labels-idx1-ubyte.gz'))\n",
    "        \n",
    "        self.train_img = self.preprocess_data(self.raw_train_img)\n",
    "        self.test_img = self.preprocess_data(self.raw_test_img)\n",
    "        \n",
    "        self.train_labels = self.one_hot_encode_labels(self.raw_train_labels)\n",
    "        self.test_labels = self.one_hot_encode_labels(self.raw_test_labels)\n",
    "        \n",
    "        self.cnn = tf.keras.models.Sequential()\n",
    "        self.cnn.add(tf.keras.layers.Conv2D(32,\n",
    "                                            kernel_size = (5,5),\n",
    "                                            strides = (2,2),\n",
    "                                            input_shape = (28, 28, 1),\n",
    "                                            activation = \"relu\"))\n",
    "        self.cnn.add(tf.keras.layers.Conv2D(64,\n",
    "                                            kernel_size = (3, 3),\n",
    "                                            activation = \"relu\"))\n",
    "        \n",
    "        self.cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "        self.cnn.add(tf.keras.layers.Flatten())\n",
    "        self.cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "        self.cnn.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "    def read_data(self, path):\n",
    "        print(\"Lese Datenset '%s' ein\" %path)\n",
    "        with gzip.open(path, \"rb\") as f:\n",
    "            z, dtype, dim = struct.unpack(\">HBB\", f.read(4))\n",
    "            print(\"Dimensions:\", dim)\n",
    "            shape = tuple(struct.unpack(\">I\", f.read(4))[0] for d in range(dim))\n",
    "            print(\"Shape:\", shape)\n",
    "            print(\"***********************************************\")\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "        \n",
    "    def show_random_image(self, data_imgs, data_labels):\n",
    "        i = random.randint(0, data_imgs.shape[0])\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.clear()\n",
    "        ax.imshow(data_imgs[i].T, cmap=\"gray\")\n",
    "        title = \"label = %d = %s\" %(data_labels[i], self.labels[data_labels[i]])\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    def preprocess_data(self, raw_data):\n",
    "        normalized_data = raw_data.astype(\"float32\")/255\n",
    "        reshaped_data = normalized_data.reshape(normalized_data.shape[0], 28, 28, 1)\n",
    "        return reshaped_data\n",
    "    \n",
    "    def one_hot_encode_labels(self, raw_labels):\n",
    "        return tf.keras.utils.to_categorical(raw_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/CRV_Postleitzahlerkennung/neural_network/emnist_dataset/emnist-byclass-train-images-idx3-ubyte.gz' ein\n",
      "Dimensions: 3\n",
      "Shape: (697932, 28, 28)\n",
      "***********************************************\n",
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/CRV_Postleitzahlerkennung/neural_network/emnist_dataset/emnist-byclass-train-labels-idx1-ubyte.gz' ein\n",
      "Dimensions: 1\n",
      "Shape: (697932,)\n",
      "***********************************************\n",
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/CRV_Postleitzahlerkennung/neural_network/emnist_dataset/emnist-byclass-test-images-idx3-ubyte.gz' ein\n",
      "Dimensions: 3\n",
      "Shape: (116323, 28, 28)\n",
      "***********************************************\n",
      "Lese Datenset '/home/isaac/Documents/master/computer_and_robot_vision/CRV_Postleitzahlerkennung/neural_network/emnist_dataset/emnist-byclass-test-labels-idx1-ubyte.gz' ein\n",
      "Dimensions: 1\n",
      "Shape: (116323,)\n",
      "***********************************************\n"
     ]
    }
   ],
   "source": [
    "model = CrvModel(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_random_image(model.raw_train_img, model.raw_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 12, 12, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 232,254\n",
      "Trainable params: 232,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.cnn.summary()\n",
    "model.cnn.compile(loss = \"categorical_crossentropy\",\n",
    "                  optimizer = \"adam\",\n",
    "                  metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 697932 samples, validate on 116323 samples\n",
      "Epoch 1/50\n",
      "697932/697932 [==============================] - 9s 12us/sample - loss: 0.8841 - accuracy: 0.7391 - val_loss: 0.4599 - val_accuracy: 0.8393\n",
      "Epoch 2/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.5073 - accuracy: 0.8273 - val_loss: 0.4109 - val_accuracy: 0.8524\n",
      "Epoch 3/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.4635 - accuracy: 0.8390 - val_loss: 0.3912 - val_accuracy: 0.8583\n",
      "Epoch 4/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.4402 - accuracy: 0.8455 - val_loss: 0.3823 - val_accuracy: 0.8603\n",
      "Epoch 5/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.4263 - accuracy: 0.8483 - val_loss: 0.3750 - val_accuracy: 0.8615\n",
      "Epoch 6/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.4167 - accuracy: 0.8512 - val_loss: 0.3697 - val_accuracy: 0.8645\n",
      "Epoch 7/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.4085 - accuracy: 0.8535 - val_loss: 0.3630 - val_accuracy: 0.8660\n",
      "Epoch 8/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.4017 - accuracy: 0.8549 - val_loss: 0.3603 - val_accuracy: 0.8673\n",
      "Epoch 9/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3963 - accuracy: 0.8568 - val_loss: 0.3586 - val_accuracy: 0.8665\n",
      "Epoch 10/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3920 - accuracy: 0.8573 - val_loss: 0.3554 - val_accuracy: 0.8676\n",
      "Epoch 11/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3889 - accuracy: 0.8584 - val_loss: 0.3544 - val_accuracy: 0.8678\n",
      "Epoch 12/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3854 - accuracy: 0.8594 - val_loss: 0.3514 - val_accuracy: 0.8696\n",
      "Epoch 13/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3816 - accuracy: 0.8602 - val_loss: 0.3524 - val_accuracy: 0.8686\n",
      "Epoch 14/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3796 - accuracy: 0.8607 - val_loss: 0.3529 - val_accuracy: 0.8683\n",
      "Epoch 15/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3769 - accuracy: 0.8617 - val_loss: 0.3498 - val_accuracy: 0.8695\n",
      "Epoch 16/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3745 - accuracy: 0.8625 - val_loss: 0.3476 - val_accuracy: 0.8702\n",
      "Epoch 17/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3727 - accuracy: 0.8626 - val_loss: 0.3483 - val_accuracy: 0.8700\n",
      "Epoch 18/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3711 - accuracy: 0.8629 - val_loss: 0.3465 - val_accuracy: 0.8705\n",
      "Epoch 19/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3693 - accuracy: 0.8632 - val_loss: 0.3484 - val_accuracy: 0.8699\n",
      "Epoch 20/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3671 - accuracy: 0.8639 - val_loss: 0.3474 - val_accuracy: 0.8699\n",
      "Epoch 21/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3656 - accuracy: 0.8643 - val_loss: 0.3467 - val_accuracy: 0.8703\n",
      "Epoch 22/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3650 - accuracy: 0.8642 - val_loss: 0.3453 - val_accuracy: 0.8710\n",
      "Epoch 23/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3632 - accuracy: 0.8650 - val_loss: 0.3443 - val_accuracy: 0.8714\n",
      "Epoch 24/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3617 - accuracy: 0.8653 - val_loss: 0.3449 - val_accuracy: 0.8709\n",
      "Epoch 25/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3609 - accuracy: 0.8653 - val_loss: 0.3438 - val_accuracy: 0.8712\n",
      "Epoch 26/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3595 - accuracy: 0.8658 - val_loss: 0.3442 - val_accuracy: 0.8707\n",
      "Epoch 27/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3577 - accuracy: 0.8665 - val_loss: 0.3437 - val_accuracy: 0.8709\n",
      "Epoch 28/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3573 - accuracy: 0.8665 - val_loss: 0.3446 - val_accuracy: 0.8716\n",
      "Epoch 29/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3564 - accuracy: 0.8669 - val_loss: 0.3438 - val_accuracy: 0.8708\n",
      "Epoch 30/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3549 - accuracy: 0.8671 - val_loss: 0.3448 - val_accuracy: 0.8714\n",
      "Epoch 31/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3544 - accuracy: 0.8674 - val_loss: 0.3418 - val_accuracy: 0.8723\n",
      "Epoch 32/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3530 - accuracy: 0.8677 - val_loss: 0.3428 - val_accuracy: 0.8721\n",
      "Epoch 33/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3528 - accuracy: 0.8674 - val_loss: 0.3414 - val_accuracy: 0.8724\n",
      "Epoch 34/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3519 - accuracy: 0.8678 - val_loss: 0.3423 - val_accuracy: 0.8716\n",
      "Epoch 35/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3507 - accuracy: 0.8677 - val_loss: 0.3416 - val_accuracy: 0.8722\n",
      "Epoch 36/50\n",
      "697932/697932 [==============================] - 8s 11us/sample - loss: 0.3508 - accuracy: 0.8683 - val_loss: 0.3407 - val_accuracy: 0.8726\n",
      "Epoch 37/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3499 - accuracy: 0.8684 - val_loss: 0.3419 - val_accuracy: 0.8717\n",
      "Epoch 38/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3486 - accuracy: 0.8683 - val_loss: 0.3413 - val_accuracy: 0.8727\n",
      "Epoch 39/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3478 - accuracy: 0.8690 - val_loss: 0.3423 - val_accuracy: 0.8728\n",
      "Epoch 40/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3471 - accuracy: 0.8694 - val_loss: 0.3425 - val_accuracy: 0.8717\n",
      "Epoch 41/50\n",
      "697932/697932 [==============================] - 7s 11us/sample - loss: 0.3466 - accuracy: 0.8693 - val_loss: 0.3407 - val_accuracy: 0.8727\n",
      "Epoch 42/50\n",
      "697932/697932 [==============================] - 7s 10us/sample - loss: 0.3465 - accuracy: 0.8697 - val_loss: 0.3406 - val_accuracy: 0.8723\n",
      "Epoch 43/50\n",
      "631808/697932 [==========================>...] - ETA: 0s - loss: 0.3450 - accuracy: 0.8698"
     ]
    }
   ],
   "source": [
    "model.trained = model.cnn.fit(model.train_img,\n",
    "              model.train_labels,\n",
    "              batch_size = model.batch_size,\n",
    "              epochs = model.epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = (model.test_img, model.test_labels))\n",
    "\n",
    "model.cnn.save(model.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), dpi=96)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model.trained.history['loss'])\n",
    "plt.plot(model.trained.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model.trained.history['accuracy'])\n",
    "plt.plot(model.trained.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
